{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Facial Expression Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Objective:\n",
    "For human beings, understanding expressions is a very easy task. But the same cannot be said for the computers. Even though there has been a tremendous growth in the Machine Learning/ AI field such that computers are proved to be more accurate than humans in a lot of tasks related to computer vision, NLP and many more. But for a computer to interpret the facial expressions has still been a difficult task for computers. In this project, we will construct a model that can interpret the facial expressions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About the Dataset:\n",
    "We will be using the famous FER2013 dataset (link for the dataset: https://www.kaggle.com/jonathanoheix/face-expression-recognition-dataset). The data consists of 35k 48x48 pixel images of faces. The faces have been automatically registered so that the face is more or less centered and occupies about the same amount of space in each image. The task is to categorize each face based on the emotion shown in the facial expression in to one of seven categories (Angry, Disgust, Fear, Happy, Sad, Surprise, Neutral).\n",
    "\n",
    "The dataset is divided into 29k training dataset and 7k testing dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For interacting with operating system\n",
    "import os\n",
    "\n",
    "# For interacting with files\n",
    "import glob\n",
    "\n",
    "# Data manipulation & Visualization\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tqdm import tqdm\n",
    "\n",
    "# For saving data\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are provided with separate train and test folders each consisting of the 7 folders namely classes. We will use these folders to create a dataframe (mixed randomly) for each train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fear', 'sad', 'disgust', 'happy', 'angry', 'neutral', 'surprise']\n"
     ]
    }
   ],
   "source": [
    "# File paths\n",
    "base_dir = os.path.join('../input/face-expression-recognition-dataset/images/images/')\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "test_dir = os.path.join(base_dir, 'validation')\n",
    "\n",
    "# List dirs under train folder\n",
    "print(os.listdir(train_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train images with expression fear:  4103\n",
      "Train images with expression sad:  4938\n",
      "Train images with expression disgust:  436\n",
      "Train images with expression happy:  7164\n",
      "Train images with expression angry:  3993\n",
      "Train images with expression neutral:  4982\n",
      "Train images with expression surprise:  3205\n",
      "\n",
      "Total number of images in Train Set:  28821\n"
     ]
    }
   ],
   "source": [
    "# Distribution of expressions in the train dataset\n",
    "for exp in os.listdir(train_dir):\n",
    "    train_files = glob.glob(os.path.join(train_dir, exp) + '/*.jpg')    \n",
    "    print('Train images with expression %s: '%(exp), len(train_files))\n",
    "    \n",
    "print('\\nTotal number of images in Train Set: ', len(glob.glob(train_dir + '/*/*.jpg')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test images with expression fear:  1018\n",
      "Test images with expression sad:  1139\n",
      "Test images with expression disgust:  111\n",
      "Test images with expression happy:  1825\n",
      "Test images with expression angry:  960\n",
      "Test images with expression neutral:  1216\n",
      "Test images with expression surprise:  797\n",
      "\n",
      "Total number of images in Test Set:  7066\n"
     ]
    }
   ],
   "source": [
    "# Distribution of expressions in the test dataset\n",
    "for exp in os.listdir(test_dir):\n",
    "    test_files = glob.glob(os.path.join(test_dir, exp) + '/*.jpg')\n",
    "    print('Test images with expression %s: '%(exp), len(test_files))\n",
    "\n",
    "print('\\nTotal number of images in Test Set: ', len(glob.glob(test_dir + '/*/*.jpg')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../input/face-expression-recognition-dataset/i...</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../input/face-expression-recognition-dataset/i...</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../input/face-expression-recognition-dataset/i...</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../input/face-expression-recognition-dataset/i...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../input/face-expression-recognition-dataset/i...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28816</th>\n",
       "      <td>../input/face-expression-recognition-dataset/i...</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28817</th>\n",
       "      <td>../input/face-expression-recognition-dataset/i...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28818</th>\n",
       "      <td>../input/face-expression-recognition-dataset/i...</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28819</th>\n",
       "      <td>../input/face-expression-recognition-dataset/i...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28820</th>\n",
       "      <td>../input/face-expression-recognition-dataset/i...</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28821 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                filename    label\n",
       "0      ../input/face-expression-recognition-dataset/i...      sad\n",
       "1      ../input/face-expression-recognition-dataset/i...      sad\n",
       "2      ../input/face-expression-recognition-dataset/i...    happy\n",
       "3      ../input/face-expression-recognition-dataset/i...     fear\n",
       "4      ../input/face-expression-recognition-dataset/i...  neutral\n",
       "...                                                  ...      ...\n",
       "28816  ../input/face-expression-recognition-dataset/i...      sad\n",
       "28817  ../input/face-expression-recognition-dataset/i...     fear\n",
       "28818  ../input/face-expression-recognition-dataset/i...    angry\n",
       "28819  ../input/face-expression-recognition-dataset/i...  neutral\n",
       "28820  ../input/face-expression-recognition-dataset/i...      sad\n",
       "\n",
       "[28821 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create train dataframe using train images \n",
    "train_angry = glob.glob(os.path.join(train_dir, 'angry') + '/*.jpg')\n",
    "train_disgust = glob.glob(os.path.join(train_dir, 'disgust') + '/*.jpg')\n",
    "train_fear = glob.glob(os.path.join(train_dir, 'fear') + '/*.jpg')\n",
    "train_happy = glob.glob(os.path.join(train_dir, 'happy') + '/*.jpg')\n",
    "train_neutral = glob.glob(os.path.join(train_dir, 'neutral') + '/*.jpg')\n",
    "train_sad = glob.glob(os.path.join(train_dir, 'sad') + '/*.jpg')\n",
    "train_surprise = glob.glob(os.path.join(train_dir, 'surprise') + '/*.jpg')\n",
    "\n",
    "np.random.seed(42)\n",
    "train = pd.DataFrame({\n",
    "    'filename': train_angry+train_disgust+train_fear+train_happy+train_neutral+train_sad+train_surprise,\n",
    "    'label': ['angry'] * len(train_angry) + ['disgust'] * len(train_disgust) + ['fear'] * len(train_fear) + \n",
    "        ['happy'] * len(train_happy) + ['neutral'] * len(train_neutral) + ['sad'] * len(train_sad) + ['surprise']*len(train_surprise)\n",
    "}).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../input/face-expression-recognition-dataset/i...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../input/face-expression-recognition-dataset/i...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../input/face-expression-recognition-dataset/i...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../input/face-expression-recognition-dataset/i...</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../input/face-expression-recognition-dataset/i...</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7061</th>\n",
       "      <td>../input/face-expression-recognition-dataset/i...</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7062</th>\n",
       "      <td>../input/face-expression-recognition-dataset/i...</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7063</th>\n",
       "      <td>../input/face-expression-recognition-dataset/i...</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7064</th>\n",
       "      <td>../input/face-expression-recognition-dataset/i...</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7065</th>\n",
       "      <td>../input/face-expression-recognition-dataset/i...</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7066 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               filename    label\n",
       "0     ../input/face-expression-recognition-dataset/i...  neutral\n",
       "1     ../input/face-expression-recognition-dataset/i...     fear\n",
       "2     ../input/face-expression-recognition-dataset/i...  neutral\n",
       "3     ../input/face-expression-recognition-dataset/i...    happy\n",
       "4     ../input/face-expression-recognition-dataset/i...    angry\n",
       "...                                                 ...      ...\n",
       "7061  ../input/face-expression-recognition-dataset/i...    happy\n",
       "7062  ../input/face-expression-recognition-dataset/i...      sad\n",
       "7063  ../input/face-expression-recognition-dataset/i...      sad\n",
       "7064  ../input/face-expression-recognition-dataset/i...      sad\n",
       "7065  ../input/face-expression-recognition-dataset/i...    angry\n",
       "\n",
       "[7066 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create test dataframe using test images\n",
    "test_angry = glob.glob(os.path.join(test_dir, 'angry') + '/*.jpg')\n",
    "test_disgust = glob.glob(os.path.join(test_dir, 'disgust') + '/*.jpg')\n",
    "test_fear = glob.glob(os.path.join(test_dir, 'fear') + '/*.jpg')\n",
    "test_happy = glob.glob(os.path.join(test_dir, 'happy') + '/*.jpg')\n",
    "test_neutral = glob.glob(os.path.join(test_dir, 'neutral') + '/*.jpg')\n",
    "test_sad = glob.glob(os.path.join(test_dir, 'sad') + '/*.jpg')\n",
    "test_surprise = glob.glob(os.path.join(test_dir, 'surprise') + '/*.jpg')\n",
    "\n",
    "np.random.seed(42)\n",
    "test = pd.DataFrame({\n",
    "    'filename': test_angry+test_disgust+test_fear+test_happy+test_neutral+test_sad+test_surprise,\n",
    "    'label': ['angry'] * len(test_angry) + ['disgust'] * len(test_disgust) + ['fear'] * len(test_fear) + \n",
    "        ['happy'] * len(test_happy) + ['neutral'] * len(test_neutral) + ['sad'] * len(test_sad) + ['surprise']*len(test_surprise)\n",
    "}).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the values from test dataframe into new varibales\n",
    "X_test = test['filename'].values\n",
    "y_test = test['label'].values\n",
    "\n",
    "# Save the values from test dataframe into new varibales\n",
    "X_train = train['filename'].values\n",
    "y_train = train['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28821,) (7066,)\n",
      "Train:  Counter({'happy': 7164, 'neutral': 4982, 'sad': 4938, 'fear': 4103, 'angry': 3993, 'surprise': 3205, 'disgust': 436})\n",
      "Test:  Counter({'happy': 1825, 'neutral': 1216, 'sad': 1139, 'fear': 1018, 'angry': 960, 'surprise': 797, 'disgust': 111})\n"
     ]
    }
   ],
   "source": [
    "# Take a look at the distribution at once \n",
    "from collections import Counter\n",
    "print(X_train.shape, X_test.shape)\n",
    "\n",
    "print('Train: ', Counter(y_train))\n",
    "print('Test: ', Counter(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above we can see, images are properly splitted accross the three datasets. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Image to Numpy Array**: Our Model will not take .JPG files as input rather an numpy array of the images. We will use keras img_to_array and load_img to convert the images to numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28821/28821 [00:59<00:00, 485.56it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7066/7066 [00:13<00:00, 522.15it/s]\n"
     ]
    }
   ],
   "source": [
    "# Convert Images to Arrays\n",
    "from keras.preprocessing.image import img_to_array, load_img\n",
    "X_train =  [img_to_array(load_img(img, grayscale=False)) for img in tqdm(X_train)]\n",
    "X_train = np.array(X_train) #changing from list to array\n",
    "\n",
    "X_test =  [img_to_array(load_img(img, grayscale=False)) for img in tqdm(X_test)]\n",
    "X_test = np.array(X_test) #changing from list to array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Training dataset:  (28821, 48, 48, 3)\n",
      "Shape of Training labels:  (28821,) \n",
      "\n",
      "Shape of Testing dataset:  (7066, 48, 48, 3)\n",
      "Shape of Testing labels:  (7066,)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of Training dataset: ', X_train.shape)\n",
    "print('Shape of Training labels: ', y_train.shape, '\\n')\n",
    "\n",
    "print('Shape of Testing dataset: ', X_test.shape)\n",
    "print('Shape of Testing labels: ', y_test.shape)\n",
    "\n",
    "#print(list(set(y_train)))\n",
    "#print(list(set(y_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Label Encoding**: Similarly as above, for labels the model will not take words of english rather numberically encoded values of those words. We will use LabelEncode from sklearn library along with to_categorical from keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode labels with value between 0 and n_classes-1.\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "le.fit(y_train)\n",
    "y_train_enc = le.transform(y_train)\n",
    "y_test_enc = le.transform(y_test)\n",
    "\n",
    "# Converts a class vector (integers) to binary class matrix.\n",
    "from keras.utils.np_utils import to_categorical\n",
    "y_train_enc = to_categorical(y_train_enc)\n",
    "y_test_enc = to_categorical(y_test_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Training Labels:  (28821, 7)\n",
      "Shape of Testing Labels:  (7066, 7)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of Training Labels: ', y_train_enc.shape)\n",
    "print('Shape of Testing Labels: ', y_test_enc.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating directory\n",
    "os.mkdir('pickle') if not os.path.isdir('pickle') else None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data using Pickle.\n",
    "#Save training data\n",
    "with open('pickle/X_train.pickle','wb') as f:\n",
    "    pickle.dump(X_train, f)\n",
    "with open('pickle/y_train_enc.pickle','wb') as f:\n",
    "    pickle.dump(y_train_enc, f)\n",
    "    \n",
    "# Save testing data\n",
    "with open('pickle/X_test.pickle','wb') as f:\n",
    "    pickle.dump(X_test, f)\n",
    "with open('pickle/y_test_enc.pickle','wb') as f:\n",
    "    pickle.dump(y_test_enc, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Training dataset:  (28821, 48, 48, 3)\n",
      "Shape of Training labels:  (28821, 7) \n",
      "\n",
      "Shape of Testing dataset:  (7066, 48, 48, 3)\n",
      "Shape of Testing labels:  (7066, 7)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of Training dataset: ', X_train.shape)\n",
    "print('Shape of Training labels: ', y_train_enc.shape, '\\n')\n",
    "\n",
    "print('Shape of Testing dataset: ', X_test.shape)\n",
    "print('Shape of Testing labels: ', y_test_enc.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
