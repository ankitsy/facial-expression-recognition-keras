{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Some basic imports\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from keras.callbacks.callbacks import EarlyStopping\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading variables\n",
    "# Get train set\n",
    "X_train = pickle.load(open('../input/final-fer/pickle/X_train.pickle','rb'))\n",
    "y_train_enc = pickle.load(open('../input/final-fer/pickle/y_train_enc.pickle','rb'))\n",
    "\n",
    "# Get test set\n",
    "X_test = pickle.load(open('../input/final-fer/pickle/X_test.pickle','rb'))\n",
    "y_test_enc = pickle.load(open('../input/final-fer/pickle/y_test_enc.pickle','rb'))\n",
    "\n",
    "# Normalize datasets\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "X_train /= 255.\n",
    "X_test /= 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Training dataset:  (28821, 48, 48, 3)\n",
      "Shape of Training labels:  (28821, 7) \n",
      "\n",
      "Shape of Testing dataset:  (7066, 48, 48, 3)\n",
      "Shape of Testing labels:  (7066, 7)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of Training dataset: ', X_train.shape)\n",
    "print('Shape of Training labels: ', y_train_enc.shape, '\\n')\n",
    "\n",
    "print('Shape of Testing dataset: ', X_test.shape)\n",
    "print('Shape of Testing labels: ', y_test_enc.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set hyperparameters\n",
    "BATCH_SIZE = 64\n",
    "NUM_CLASSES = 7\n",
    "EPOCHS = 100\n",
    "INPUT_SHAPE = (48,48,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 46, 46, 64)        1792      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 46, 46, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 46, 46, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 23, 23, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 23, 23, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 23, 23, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 23, 23, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 23, 23, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 23, 23, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 11, 11, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 11, 11, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 11, 11, 256)       295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 11, 11, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 11, 11, 256)       590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 11, 11, 256)       1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 5, 5, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 5, 5, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 5, 5, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 5, 5, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 5, 5, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 5, 5, 512)         2048      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               1049088   \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 7)                 903       \n",
      "=================================================================\n",
      "Total params: 5,907,015\n",
      "Trainable params: 5,903,303\n",
      "Non-trainable params: 3,712\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Model Architecture\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', input_shape=INPUT_SHAPE, data_format='channels_last', kernel_regularizer=l2(0.01)))\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv2D(256, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(256, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv2D(512, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(512, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(NUM_CLASSES, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "#Compliling the model with adam optimixer and categorical crossentropy loss\n",
    "model.compile(loss=categorical_crossentropy,\n",
    "              optimizer=Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-7),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "28821/28821 [==============================] - 24s 827us/step - loss: 2.0119 - accuracy: 0.2148\n",
      "Epoch 2/100\n",
      "28821/28821 [==============================] - 19s 665us/step - loss: 1.8546 - accuracy: 0.2442\n",
      "Epoch 3/100\n",
      "28821/28821 [==============================] - 19s 661us/step - loss: 1.8213 - accuracy: 0.2551\n",
      "Epoch 4/100\n",
      "28821/28821 [==============================] - 19s 661us/step - loss: 1.7406 - accuracy: 0.2995\n",
      "Epoch 5/100\n",
      "28821/28821 [==============================] - 19s 661us/step - loss: 1.6318 - accuracy: 0.3498\n",
      "Epoch 6/100\n",
      "28821/28821 [==============================] - 19s 661us/step - loss: 1.5352 - accuracy: 0.3912\n",
      "Epoch 7/100\n",
      "28821/28821 [==============================] - 19s 661us/step - loss: 1.4812 - accuracy: 0.4193\n",
      "Epoch 8/100\n",
      "28821/28821 [==============================] - 19s 661us/step - loss: 1.4290 - accuracy: 0.4453\n",
      "Epoch 9/100\n",
      "28821/28821 [==============================] - 19s 660us/step - loss: 1.3949 - accuracy: 0.4643\n",
      "Epoch 10/100\n",
      "28821/28821 [==============================] - 19s 660us/step - loss: 1.3530 - accuracy: 0.4827\n",
      "Epoch 11/100\n",
      "28821/28821 [==============================] - 19s 660us/step - loss: 1.3188 - accuracy: 0.5005\n",
      "Epoch 12/100\n",
      "28821/28821 [==============================] - 19s 661us/step - loss: 1.2880 - accuracy: 0.5152\n",
      "Epoch 13/100\n",
      "28821/28821 [==============================] - 19s 660us/step - loss: 1.2575 - accuracy: 0.5295\n",
      "Epoch 14/100\n",
      "28821/28821 [==============================] - 19s 661us/step - loss: 1.2446 - accuracy: 0.5365\n",
      "Epoch 15/100\n",
      "28821/28821 [==============================] - 19s 660us/step - loss: 1.2212 - accuracy: 0.5481\n",
      "Epoch 16/100\n",
      "28821/28821 [==============================] - 19s 659us/step - loss: 1.1902 - accuracy: 0.5655\n",
      "Epoch 17/100\n",
      "28821/28821 [==============================] - 19s 672us/step - loss: 1.1736 - accuracy: 0.5670\n",
      "Epoch 18/100\n",
      "28821/28821 [==============================] - 19s 665us/step - loss: 1.1436 - accuracy: 0.5812\n",
      "Epoch 19/100\n",
      "28821/28821 [==============================] - 19s 660us/step - loss: 1.1256 - accuracy: 0.5866\n",
      "Epoch 20/100\n",
      "28821/28821 [==============================] - 19s 662us/step - loss: 1.0984 - accuracy: 0.6015\n",
      "Epoch 21/100\n",
      "28821/28821 [==============================] - 19s 659us/step - loss: 1.0807 - accuracy: 0.6109\n",
      "Epoch 22/100\n",
      "28821/28821 [==============================] - 19s 660us/step - loss: 1.0612 - accuracy: 0.6171\n",
      "Epoch 23/100\n",
      "28821/28821 [==============================] - 19s 660us/step - loss: 1.0396 - accuracy: 0.6258\n",
      "Epoch 24/100\n",
      "28821/28821 [==============================] - 19s 661us/step - loss: 1.0244 - accuracy: 0.6327\n",
      "Epoch 25/100\n",
      "28821/28821 [==============================] - 19s 659us/step - loss: 1.0009 - accuracy: 0.6382\n",
      "Epoch 26/100\n",
      "28821/28821 [==============================] - 19s 659us/step - loss: 0.9903 - accuracy: 0.6402\n",
      "Epoch 27/100\n",
      "28821/28821 [==============================] - 19s 660us/step - loss: 0.9659 - accuracy: 0.6509\n",
      "Epoch 28/100\n",
      "28821/28821 [==============================] - 19s 661us/step - loss: 0.9496 - accuracy: 0.6591\n",
      "Epoch 29/100\n",
      "28821/28821 [==============================] - 19s 662us/step - loss: 0.9326 - accuracy: 0.6622\n",
      "Epoch 30/100\n",
      "28821/28821 [==============================] - 19s 658us/step - loss: 0.9215 - accuracy: 0.6684\n",
      "Epoch 31/100\n",
      "28821/28821 [==============================] - 19s 659us/step - loss: 0.9085 - accuracy: 0.6758\n",
      "Epoch 32/100\n",
      "28821/28821 [==============================] - 19s 659us/step - loss: 0.8970 - accuracy: 0.6778\n",
      "Epoch 33/100\n",
      "28821/28821 [==============================] - 19s 672us/step - loss: 0.8619 - accuracy: 0.6866\n",
      "Epoch 34/100\n",
      "28821/28821 [==============================] - 19s 662us/step - loss: 0.8617 - accuracy: 0.6902\n",
      "Epoch 35/100\n",
      "28821/28821 [==============================] - 19s 659us/step - loss: 0.8433 - accuracy: 0.6992\n",
      "Epoch 36/100\n",
      "28821/28821 [==============================] - 19s 660us/step - loss: 0.8211 - accuracy: 0.7055\n",
      "Epoch 37/100\n",
      "28821/28821 [==============================] - 19s 659us/step - loss: 0.8172 - accuracy: 0.7082\n",
      "Epoch 38/100\n",
      "28821/28821 [==============================] - 19s 659us/step - loss: 0.8074 - accuracy: 0.7125\n",
      "Epoch 39/100\n",
      "28821/28821 [==============================] - 19s 659us/step - loss: 0.7912 - accuracy: 0.7177\n",
      "Epoch 40/100\n",
      "28821/28821 [==============================] - 19s 658us/step - loss: 0.7742 - accuracy: 0.7251\n",
      "Epoch 41/100\n",
      "28821/28821 [==============================] - 19s 660us/step - loss: 0.7675 - accuracy: 0.7278\n",
      "Epoch 42/100\n",
      "28821/28821 [==============================] - 19s 657us/step - loss: 0.7448 - accuracy: 0.7387\n",
      "Epoch 43/100\n",
      "28821/28821 [==============================] - 19s 658us/step - loss: 0.7401 - accuracy: 0.7407\n",
      "Epoch 44/100\n",
      "28821/28821 [==============================] - 19s 659us/step - loss: 0.7216 - accuracy: 0.7449\n",
      "Epoch 45/100\n",
      "28821/28821 [==============================] - 19s 659us/step - loss: 0.7114 - accuracy: 0.7512\n",
      "Epoch 46/100\n",
      "28821/28821 [==============================] - 19s 659us/step - loss: 0.6954 - accuracy: 0.7530\n",
      "Epoch 47/100\n",
      "28821/28821 [==============================] - 19s 658us/step - loss: 0.7013 - accuracy: 0.7552\n",
      "Epoch 48/100\n",
      "28821/28821 [==============================] - 19s 658us/step - loss: 0.6793 - accuracy: 0.7612\n",
      "Epoch 49/100\n",
      "28821/28821 [==============================] - 19s 670us/step - loss: 0.6661 - accuracy: 0.7654\n",
      "Epoch 50/100\n",
      "28821/28821 [==============================] - 19s 661us/step - loss: 0.6588 - accuracy: 0.7723\n",
      "Epoch 51/100\n",
      "28821/28821 [==============================] - 19s 661us/step - loss: 0.6410 - accuracy: 0.7752\n",
      "Epoch 52/100\n",
      "28821/28821 [==============================] - 19s 659us/step - loss: 0.6324 - accuracy: 0.7815\n",
      "Epoch 53/100\n",
      "28821/28821 [==============================] - 19s 660us/step - loss: 0.6308 - accuracy: 0.7832\n",
      "Epoch 54/100\n",
      "28821/28821 [==============================] - 19s 658us/step - loss: 0.6129 - accuracy: 0.7883\n",
      "Epoch 55/100\n",
      "28821/28821 [==============================] - 19s 658us/step - loss: 0.6143 - accuracy: 0.7873\n",
      "Epoch 56/100\n",
      "28821/28821 [==============================] - 19s 658us/step - loss: 0.5930 - accuracy: 0.7932\n",
      "Epoch 57/100\n",
      "28821/28821 [==============================] - 19s 657us/step - loss: 0.5827 - accuracy: 0.7998\n",
      "Epoch 58/100\n",
      "28821/28821 [==============================] - 19s 660us/step - loss: 0.5763 - accuracy: 0.8037\n",
      "Epoch 59/100\n",
      "28821/28821 [==============================] - 19s 657us/step - loss: 0.5670 - accuracy: 0.8062\n",
      "Epoch 60/100\n",
      " 1600/28821 [>.............................] - ETA: 17s - loss: 0.5538 - accuracy: 0.8200"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history_cnn = model.fit(X_train, y_train_enc,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    epochs=EPOCHS,\n",
    "                    verbose=1,\n",
    "                    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'History' object has no attribute 'save'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-8d4893e53a3c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Save the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhistory_cnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'fer_cnn.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'History' object has no attribute 'save'"
     ]
    }
   ],
   "source": [
    "# Save the model\n",
    "history_cnn.save('fer_cnn.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions in a variable\n",
    "y_pred = history_cnn.model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted and true label values saved\n",
      "Accuracy on test set :65.6241154825927%\n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "truey=[]\n",
    "predy=[]\n",
    "\n",
    "yh = y_pred.tolist()\n",
    "yt = y_test_enc.tolist()\n",
    "count = 0\n",
    "\n",
    "for i in range(len(y_test_enc)):\n",
    "    yy = max(yh[i])\n",
    "    yyt = max(yt[i])\n",
    "    predy.append(yh[i].index(yy))\n",
    "    truey.append(yt[i].index(yyt))\n",
    "    if(yh[i].index(yy)== yt[i].index(yyt)):\n",
    "        count+=1\n",
    "        \n",
    "acc = (count/len(y_test_enc))*100\n",
    "np.save('truey', truey)\n",
    "np.save('predy', predy)\n",
    "print(\"Predicted and true label values saved\")\n",
    "print(\"Accuracy on test set :\"+str(acc)+\"%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
